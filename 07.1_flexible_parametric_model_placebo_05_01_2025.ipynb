{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9876c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Optional, Tuple, Dict   \n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter, NelsonAalenFitter\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import gaussian_kde, norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from rpy2.robjects import r\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects import default_converter\n",
    "from rpy2.robjects import pandas2ri, conversion\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import Formula\n",
    "from rpy2.robjects.vectors import FloatVector, IntVector, ListVector, Vector, StrVector\n",
    "from rpy2.robjects import DataFrame, IntVector\n",
    "\n",
    "rstpm2 = importr(\"rstpm2\")\n",
    "survival = importr(\"survival\")\n",
    "ggplot2 = importr(\"ggplot2\")\n",
    "graphics = importr(\"graphics\")\n",
    "stats = importr(\"stats\")\n",
    "lmtest = importr(\"lmtest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b90029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1678, 13)\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1678 entries, 0 to 1677\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   subject_id        1678 non-null   object \n",
      " 1   Event             1678 non-null   float64\n",
      " 2   Vital_capacity    1678 non-null   float64\n",
      " 3   Sex               1678 non-null   object \n",
      " 4   Onset_site        1678 non-null   object \n",
      " 5   Study_Arm         1678 non-null   object \n",
      " 6   European          1678 non-null   int64  \n",
      " 7   Age               1678 non-null   float64\n",
      " 8   Diagnostic_Delay  1678 non-null   float64\n",
      " 9   Disease_Duration  1678 non-null   float64\n",
      " 10  TRICALS           1678 non-null   float64\n",
      " 11  Study_id          1678 non-null   object \n",
      " 12  Expt              1678 non-null   object \n",
      "dtypes: float64(6), int64(1), object(6)\n",
      "memory usage: 170.6+ KB\n",
      "None\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>Event</th>\n",
       "      <th>Vital_capacity</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Onset_site</th>\n",
       "      <th>Study_Arm</th>\n",
       "      <th>European</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diagnostic_Delay</th>\n",
       "      <th>Disease_Duration</th>\n",
       "      <th>TRICALS</th>\n",
       "      <th>Study_id</th>\n",
       "      <th>Expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P01001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Limb</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>1</td>\n",
       "      <td>54.762491</td>\n",
       "      <td>13.600526</td>\n",
       "      <td>32.600526</td>\n",
       "      <td>-4.921357</td>\n",
       "      <td>lica</td>\n",
       "      <td>licals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P01002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Limb</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>1</td>\n",
       "      <td>61.160849</td>\n",
       "      <td>20.137976</td>\n",
       "      <td>41.538765</td>\n",
       "      <td>-6.347018</td>\n",
       "      <td>lica</td>\n",
       "      <td>licals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P01003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Male</td>\n",
       "      <td>Limb</td>\n",
       "      <td>Active</td>\n",
       "      <td>1</td>\n",
       "      <td>46.702259</td>\n",
       "      <td>15.571616</td>\n",
       "      <td>34.571616</td>\n",
       "      <td>-6.373852</td>\n",
       "      <td>lica</td>\n",
       "      <td>licals</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject_id  Event  Vital_capacity     Sex Onset_site Study_Arm  European  \\\n",
       "0     P01001    0.0           107.0    Male       Limb   Placebo         1   \n",
       "1     P01002    1.0            99.0  Female       Limb   Placebo         1   \n",
       "2     P01003    0.0           102.0    Male       Limb    Active         1   \n",
       "\n",
       "         Age  Diagnostic_Delay  Disease_Duration   TRICALS Study_id    Expt  \n",
       "0  54.762491         13.600526         32.600526 -4.921357     lica  licals  \n",
       "1  61.160849         20.137976         41.538765 -6.347018     lica  licals  \n",
       "2  46.702259         15.571616         34.571616 -6.373852     lica  licals  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('/Users/Apple/projects/ALS_Digital_Twins/All_processed_data/Results/combined_other_datasets_for_modeling.csv')\n",
    "df = dfs.copy()\n",
    "\n",
    "print(df.shape)\n",
    "print()\n",
    "print(df.info())\n",
    "print()\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b75d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expt: {'riluzole': 1282, 'mirocals': 220, 'licals': 176}\n",
      "\n",
      "Study_id: {'301': 959, 'miro': 220, 'lica': 176, '302': 168, '216': 155}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Expt: {df['Expt'].value_counts().to_dict()}\\n\")\n",
    "print(f\"Study_id: {df['Study_id'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1809b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Expt'] != 'riluzole']\n",
    "df = df[df['Study_Arm'] == 'Placebo']\n",
    "print(f\"Expt: {df['Expt'].value_counts().to_dict()}\\n\")\n",
    "print(f\"Study_id: {df['Study_id'].value_counts().to_dict()}\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ages'] = (df['Age'] - df['Age'].mean()) / df['Age'].std()\n",
    "df['TRICALSs'] = (df['TRICALS'] - df['TRICALS'].mean()) / df['TRICALS'].std()\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_var = df[['Disease_Duration', 'Diagnostic_Delay', 'Vital_capacity']]\n",
    "df_time_var.describe()\n",
    "# df_time.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d93869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Disease_Durationl'] = np.log1p(df['Disease_Duration']) # ln(1 + x)\n",
    "df['Diagnostic_Delayl'] = np.log1p(df['Diagnostic_Delay']) # ln(1 + x)\n",
    "df['Vital_capacityl'] = np.log(df['Vital_capacity']) # ln(x)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dccf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Disease_Durationls'] = (df['Disease_Durationl'] - df['Disease_Durationl'].mean()) / df['Disease_Durationl'].std()\n",
    "df['Diagnostic_Delayls'] = (df['Diagnostic_Delayl'] - df['Diagnostic_Delayl'].mean()) / df['Diagnostic_Delayl'].std()\n",
    "df['Vital_capacityls'] = (df['Vital_capacityl'] - df['Vital_capacityl'].mean()) / df['Vital_capacityl'].std()\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ebfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df[['Disease_Durationls', 'Diagnostic_Delayls', 'Vital_capacityls']]\n",
    "df_time.describe()\n",
    "\n",
    "# Plot histogram and density\n",
    "cols = df_time.columns\n",
    "n_per_row = 3\n",
    "n_rows = int(np.ceil(len(cols) / n_per_row))\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, n_per_row,\n",
    "    figsize=(4 * n_per_row, 3 * n_rows)\n",
    ")\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, col in zip(axes, cols):\n",
    "    data = df_time[col].dropna()\n",
    "\n",
    "    ax.hist(data, bins=20, density=True, edgecolor='skyblue')\n",
    "\n",
    "    kde = gaussian_kde(data)\n",
    "    x = np.linspace(data.min(), data.max(), 300)\n",
    "    ax.plot(x, kde(x))\n",
    "\n",
    "    ax.set_title(col)\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "for ax in axes[len(cols):]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09727a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['European'] = df['European'].astype('int')\n",
    "df['Event'] = df['Event'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d9d595",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Event', 'Expt', 'Onset_site', 'Sex', 'Study_Arm', 'European']\n",
    "for col in cols:\n",
    "    print(f'{col}: {df[col].value_counts().to_dict()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'Limb': 'Limb', 'Bulbar': 'Bulbar', 'Other': 'Limb', '1.0': 'Limb',\n",
    "           '0.0': 'Bulbar', '2.0': 'Bulbar', 1.0: 'Limb', 0.0: 'Bulbar'}\n",
    "\n",
    "df['Onset_site'] = df['Onset_site'].map(mapping)\n",
    "\n",
    "#________\n",
    "mapping1 = {'M': 'Male', 'F': 'Female', 'Male': 'Male','Female': 'Female', '1': 'Male', '0': 'Female'}\n",
    "\n",
    "df['Sex'] = df['Sex'].map(mapping1)\n",
    "\n",
    "#________\n",
    "mapping2 = {'IL2': 'Active', 'ACTIVE': 'Active','PLACEBO': 'Placebo', \n",
    "            'Active': 'Active','Placebo': 'Placebo'}\n",
    "\n",
    "df['Study_Arm'] = df['Study_Arm'].map(mapping2)\n",
    "\n",
    "#________\n",
    "df['European'] = np.where(df['European'] == 0, 'Non-European', 'European')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354cbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Expt', 'Onset_site', 'Sex', 'Study_Arm', 'European']\n",
    "for col in cols:\n",
    "    print(f'{col}: {df[col].value_counts().to_dict()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d21b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "cat_cols = ['Onset_site', 'European', 'Sex', 'Expt']\n",
    "\n",
    "# One-hot encode\n",
    "df_onehot = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "df_onehot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7125d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Onset_site_Limb', 'European_Non-European', 'Sex_Male', 'Expt_mirocals']\n",
    "\n",
    "# Convert one-hot encoded columns to int\n",
    "for col in cols:\n",
    "    df_onehot[col] = df_onehot[col].astype(int)\n",
    "\n",
    "df_onehot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd2dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactions\n",
    "df_onehot['Sex_onset'] = df_onehot['Sex_Male']*df_onehot['Onset_site_Limb']\n",
    "df_onehot['Age_Sex'] = df_onehot['Sex_Male']*df_onehot['Ages']\n",
    "df_onehot['Age_onset'] = df_onehot['Ages']*df_onehot['Onset_site_Limb']\n",
    "df_onehot['Age_TRICALS'] = df_onehot['Ages']*df_onehot['TRICALSs']\n",
    "# df_onehot['Trical : Placebo Arm'] = df_onehot['TRICALS']*df_onehot['Study_Arm_Placebo']\n",
    "\n",
    "# df_onehot.info()\n",
    "df_onehot.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaa57ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_onehot.copy()\n",
    "\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64c3943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['subject_id', 'Event', 'Disease_Duration', 'Expt_mirocals', 'Study_id', \n",
    "       'Ages', 'TRICALSs', 'Diagnostic_Delayls', 'Vital_capacityls', 'Onset_site_Limb', 'European_Non-European', 'Sex_Male',\n",
    "       'Sex_onset', 'Age_Sex', 'Age_onset', 'Age_TRICALS']]\n",
    "\n",
    "df1 = df1.rename(columns={'Ages': 'Age',\n",
    "                        'Vital_capacityls': 'Vital_capacity',\n",
    "                        'Diagnostic_Delayls': 'Diagnostic_Delay',\n",
    "                        'TRICALSs': 'TRICALS',\n",
    "                        'European_Non-European': 'European_Yes',\n",
    "                        'Onset_site_Limb': 'Onset_Limb',\n",
    "                        'Sex_1': 'Sex_Male'\n",
    "                        })\n",
    "\n",
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739847f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('/Users/Apple/projects/ALS_Digital_Twins/All_processed_data/Results/processed_data_placebo_for_flexible_parametric_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Test split\n",
    "print(df1.shape)\n",
    "\n",
    "# Separate features from survival info\n",
    "X = df1.drop(columns=['Disease_Duration', 'Event'])\n",
    "y_duration = df1['Disease_Duration']\n",
    "y_event = df1['Event']\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_duration_train, y_duration_test, y_event_train, y_event_test = train_test_split(\n",
    "    X, y_duration, y_event, test_size=0.25, random_state=4\n",
    ")\n",
    "\n",
    "# Combine back for lifelines format\n",
    "train_df = X_train.copy()\n",
    "train_df['Disease_Duration'] = y_duration_train\n",
    "train_df['Event'] = y_event_train\n",
    "\n",
    "test_df = X_test.copy()\n",
    "test_df['Disease_Duration'] = y_duration_test\n",
    "test_df['Event'] = y_event_test\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conversion.localconverter(pandas2ri.converter):\n",
    "    r_df_train = pandas2ri.py2rpy(train_df)\n",
    "\n",
    "with conversion.localconverter(pandas2ri.converter):\n",
    "    r_df_test = pandas2ri.py2rpy(test_df)\n",
    "\n",
    "# with conversion.localconverter(pandas2ri.converter):\n",
    "#     r_df = pandas2ri.py2rpy(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0751e37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e0b1b31",
   "metadata": {},
   "source": [
    "#### CV Backward stepwise selection based on AIC and spline df selection\n",
    "<!-- ##### investigate the code further -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2acb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate covariates (modify for your dataset)\n",
    "covariates = [\n",
    "    'Age', 'TRICALS', 'Diagnostic_Delay',\n",
    "       'Vital_capacity', 'Onset_Limb', 'Sex_Male', 'Sex_onset',\n",
    "       'Age_Sex', 'Age_onset', 'Age_TRICALS','Expt_mirocals'\n",
    "    ]\n",
    "\n",
    "df_candidates = [0,1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8dad17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_aic_for_model(df_python, vars_list, spline_df, n_splits=5):\n",
    "    \"\"\"\n",
    "    Compute mean cross-validated AIC for a given variable set and spline df\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    aics = []\n",
    "\n",
    "    rhs = \" + \".join(vars_list) if vars_list else \"1\"\n",
    "    formula_str = f\"Surv(Disease_Duration, Event==1) ~ {rhs}\"\n",
    "    formula = Formula(formula_str)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(df_python):\n",
    "        train_df = df_python.iloc[train_idx]\n",
    "\n",
    "        # Convert fold to R\n",
    "        with localconverter(default_converter + pandas2ri.converter):\n",
    "            r_train = pandas2ri.py2rpy(train_df)\n",
    "\n",
    "        try:\n",
    "            model = rstpm2.stpm2(formula, data=r_train, df=spline_df)\n",
    "            aic = stats.AIC(model)[0]\n",
    "            aics.append(aic)\n",
    "        except Exception:\n",
    "            aics.append(np.inf)\n",
    "\n",
    "    return np.mean(aics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b86eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "\n",
    "current_vars = covariates.copy()\n",
    "best_score = np.inf\n",
    "best_vars = current_vars\n",
    "best_df = None\n",
    "\n",
    "while True:\n",
    "    candidates = []\n",
    "\n",
    "    # Try current model with different dfs\n",
    "    for df_spline in df_candidates:\n",
    "        score = cv_aic_for_model(train_df, current_vars, df_spline, n_splits)\n",
    "        candidates.append((score, current_vars, df_spline))\n",
    "\n",
    "    # Try removing each variable\n",
    "    for var in current_vars:\n",
    "        test_vars = [v for v in current_vars if v != var]\n",
    "        for df_spline in df_candidates:\n",
    "            score = cv_aic_for_model(train_df, test_vars, df_spline, n_splits)\n",
    "            candidates.append((score, test_vars, df_spline))\n",
    "\n",
    "    # Pick best candidate\n",
    "    best_candidate = min(candidates, key=lambda x: x[0])\n",
    "\n",
    "    cand_score, cand_vars, cand_df = best_candidate\n",
    "\n",
    "    # Stop if no improvement\n",
    "    if cand_score >= best_score:\n",
    "        break\n",
    "\n",
    "    best_score = cand_score\n",
    "    best_vars = cand_vars\n",
    "    best_df = cand_df\n",
    "    current_vars = cand_vars\n",
    "\n",
    "print(\"\\n Selected model by CV-AIC:\")\n",
    "print(\"Variables:\", best_vars)\n",
    "print(\"Spline df:\", best_df)\n",
    "print(\"CV-AIC:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54ad8b",
   "metadata": {},
   "source": [
    "### *Fit a flexible parametric survival model (baseline model) -  The baseline log-cumulative-hazard* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c0aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula\n",
    "formula = Formula('Surv(Disease_Duration, Event==1) ~ Age  + Sex_Male + Onset_Limb + Expt_mirocals + Diagnostic_Delay')\n",
    "\n",
    "# Fit the flexible parametric model\n",
    "# df = degrees of freedom for spline, adjust as needed\n",
    "fp_model = rstpm2.stpm2(formula, data=r_df_train, df=0)\n",
    "print(ro.r.summary(fp_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefc798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula\n",
    "formula = Formula('Surv(Disease_Duration, Event==1) ~ Age  + Sex_Male + Onset_Limb + TRICALS + Expt_mirocals + Diagnostic_Delay')\n",
    "\n",
    "# Fit the flexible parametric model\n",
    "# df = degrees of freedom for spline, adjust as needed\n",
    "fp_model = rstpm2.stpm2(formula, data=r_df_train, df=0)\n",
    "print(ro.r.summary(fp_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b150152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients directly\n",
    "summary = ro.r.summary(fp_model)\n",
    "\n",
    "# Try using slotNames to see what's available\n",
    "# print(\"Available slots:\", ro.r.slotNames(summary))\n",
    "\n",
    "# Extract using the correct slot name (usually 'coef' or 'coefficients')\n",
    "coefficients = summary.slots['coef']\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_coef = pd.DataFrame(\n",
    "    np.array(coefficients),\n",
    "    columns=['Estimate', 'Std. Error', 'z value', 'Pr(z)'],\n",
    "    index=list(coefficients.rownames)\n",
    ")\n",
    "\n",
    "df_coef = df_coef.iloc[1: -1]\n",
    "df_coef = df_coef.reset_index().rename(columns={\"index\": \"Variable\"})\n",
    "\n",
    "\n",
    "print(df_coef)\n",
    "\n",
    "#--------------------------------------\n",
    "z = 1.96  # 95% CI\n",
    "\n",
    "df_coef[\"HR\"] = (df_coef[\"Estimate\"])\n",
    "df_coef[\"CI_lower\"] = (df_coef[\"Estimate\"] - z * df_coef[\"Std. Error\"])\n",
    "df_coef[\"CI_upper\"] = (df_coef[\"Estimate\"] + z * df_coef[\"Std. Error\"])\n",
    "\n",
    "#--------------------------------------\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "ypos = np.arange(len(df_coef))\n",
    "\n",
    "# Confidence intervals\n",
    "plt.hlines(\n",
    "    y=ypos,\n",
    "    xmin=df_coef[\"CI_lower\"],\n",
    "    xmax=df_coef[\"CI_upper\"]\n",
    ")\n",
    "\n",
    "# Point estimates\n",
    "plt.plot(df_coef[\"Estimate\"], ypos, \"o\")\n",
    "\n",
    "# Vertical reference line at 0\n",
    "plt.axvline(0, linestyle=\"--\")\n",
    "\n",
    "plt.yticks(ypos, df_coef[\"Variable\"])\n",
    "plt.xlabel(\"Log Hazard Ratio\")\n",
    "plt.title(\"Forest Plot of Model Coefficients\")\n",
    "\n",
    "plt.gca().invert_yaxis()  # top-to-bottom\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common time points for prediction\n",
    "times = np.linspace(0, df1[\"Disease_Duration\"].max(), 100)\n",
    "\n",
    "# Helper to create newdata for prediction given a dataframe (train or test)\n",
    "def make_newdata(df):\n",
    "    mean_Age = df[\"Age\"].mean()\n",
    "    mean_TRICALS = df[\"TRICALS\"].mean()\n",
    "    mean_Vital = df[\"Vital_capacity\"].mean()\n",
    "    mean_Delay = df[\"Diagnostic_Delay\"].mean()\n",
    "\n",
    "    mode_Onset = df[\"Onset_Limb\"].mode()[0]\n",
    "    mode_Sex_Male = df[\"Sex_Male\"].mode()[0]\n",
    "    # mode_Sex_onset = df[\"Sex_onset\"].mode()[0]\n",
    "    mode_Expt = df[\"Expt_mirocals\"].mode()[0]\n",
    "    # mode_Study_Arm_Placebo = df[\"Study_Arm_Placebo\"].mode()[0]\n",
    "\n",
    "    with localconverter(default_converter + pandas2ri.converter):\n",
    "        newdata_r = DataFrame({\n",
    "            \"Age\": FloatVector([mean_Age]*len(times)),\n",
    "            \"Onset_Limb\": IntVector([mode_Onset]*len(times)),\n",
    "            \"TRICALS\": FloatVector([mean_TRICALS]*len(times)),\n",
    "            \"Vital_capacity\": FloatVector([mean_Vital]*len(times)),\n",
    "            \"Sex_Male\": IntVector([mode_Sex_Male]*len(times)),\n",
    "            # \"Sex_onset\": IntVector([mode_Sex_onset]*len(times)),\n",
    "            \"Expt_mirocals\": IntVector([mode_Expt]*len(times)),\n",
    "            # \"Study_Arm_Placebo\": IntVector([mode_Study_Arm_Placebo]*len(times)),\n",
    "            \"Diagnostic_Delay\": FloatVector([mean_Delay]*len(times)),\n",
    "            \"Disease_Duration\": FloatVector(times)\n",
    "        })\n",
    "    return newdata_r\n",
    "\n",
    "# Prepare newdata for train and test\n",
    "newdata_train = make_newdata(train_df)\n",
    "newdata_test = make_newdata(test_df)\n",
    "\n",
    "# Predict survival probabilities using the fitted model\n",
    "r_predict = ro.r['predict']\n",
    "\n",
    "S_train = r_predict(fp_model, newdata=newdata_train, type=\"surv\")\n",
    "S_test = r_predict(fp_model, newdata=newdata_test, type=\"surv\")\n",
    "\n",
    "with localconverter(default_converter + pandas2ri.converter):\n",
    "    py_S_train = np.array(S_train)\n",
    "    py_S_test = np.array(S_test)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(times, py_S_train, label=\"Train set (average patient)\", color='blue')\n",
    "plt.plot(times, py_S_test, label=\"Test set (average patient)\", color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Disease Duration\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title(\"Royston–Parmar Flexible Parametric Model - Spline df=0\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_train = r_predict(fp_model, newdata=newdata_train, type=\"hazard\")\n",
    "S_test = r_predict(fp_model, newdata=newdata_test, type=\"hazard\")\n",
    "\n",
    "with localconverter(default_converter + pandas2ri.converter):\n",
    "    py_S_train = np.array(S_train)\n",
    "    py_S_test = np.array(S_test)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(times, py_S_train, label=\"Train set (average patient)\", color='blue')\n",
    "plt.plot(times, py_S_test, label=\"Test set (average patient)\", color='red', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Disease Duration\")\n",
    "plt.ylabel(\"Hazard\")\n",
    "plt.ylim(0, 0.3)\n",
    "plt.title(\"Royston–Parmar Flexible Parametric Model - Spline df=0\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.linspace(0, df1[\"Disease_Duration\"].max(), 100)\n",
    "times_r = FloatVector(times)\n",
    "\n",
    "def make_newdata_category(df1, col):\n",
    "    mean_Age = df1[\"Age\"].mean()\n",
    "    mean_TRICALS = df1[\"TRICALS\"].mean()\n",
    "    mean_Vital = df1[\"Vital_capacity\"].mean()\n",
    "    mean_Delay = df1[\"Diagnostic_Delay\"].mean()\n",
    "\n",
    "    mode_Onset = df1[\"Onset_Limb\"].mode()[0]\n",
    "    # mode_Sex_onset = df1[\"Sex_onset\"].mode()[0]\n",
    "    mode_Expt = df1[\"Expt_mirocals\"].mode()[0]\n",
    "    # mode_Study_Arm_Placebo = df1[\"Study_Arm_Placebo\"].mode()[0]\n",
    "    mean_Sex_Male = int(round(df1[\"Sex_Male\"].mean()))\n",
    "\n",
    "# ────────────────────────────────────────────────────\n",
    "    # Choose the two Expt levels you want to compare\n",
    "    level0 = df1[col].unique()[0]\n",
    "    level1 = df1[col].unique()[1]\n",
    "\n",
    "    with localconverter(default_converter + pandas2ri.converter):\n",
    "    # Group 0\n",
    "        newdata0 = DataFrame({\n",
    "            \"Age\": FloatVector([mean_Age]*len(times)),\n",
    "            \"Onset_Limb\": IntVector([mode_Onset]*len(times)),\n",
    "            \"TRICALS\": FloatVector([mean_TRICALS]*len(times)),\n",
    "            \"Vital_capacity\": FloatVector([mean_Vital]*len(times)),\n",
    "            \"Sex_Male\": IntVector([mean_Sex_Male]*len(times)),\n",
    "            # \"Study_Arm_Placebo\": IntVector([mode_Study_Arm_Placebo]*len(times)),\n",
    "            # \"Sex_onset\": FloatVector([mode_Sex_onset]*len(times)),\n",
    "            \"Expt_mirocals\": IntVector([level0]*len(times)),\n",
    "            \"Diagnostic_Delay\": FloatVector([mean_Delay]*len(times)),\n",
    "            \"Disease_Duration\": times_r\n",
    "        })\n",
    "\n",
    "    with localconverter(default_converter + pandas2ri.converter):\n",
    "    # Group 1\n",
    "        newdata1 = DataFrame({\n",
    "            \"Age\": FloatVector([mean_Age]*len(times)),\n",
    "            \"Onset_Limb\": IntVector([mode_Onset]*len(times)),\n",
    "            \"TRICALS\": FloatVector([mean_TRICALS]*len(times)),\n",
    "            \"Vital_capacity\": FloatVector([mean_Vital]*len(times)),\n",
    "            \"Sex_Male\": IntVector([mean_Sex_Male]*len(times)),\n",
    "            # \"Study_Arm_Placebo\": IntVector([mode_Study_Arm_Placebo]*len(times)),\n",
    "            # \"Sex_onset\": FloatVector([mode_Sex_onset]*len(times)),\n",
    "            \"Expt_mirocals\": IntVector([level1]*len(times)),\n",
    "            \"Diagnostic_Delay\": FloatVector([mean_Delay]*len(times)),\n",
    "            \"Disease_Duration\": times_r\n",
    "        })\n",
    "    return newdata0, newdata1\n",
    "newdata_0_train, newdata_1_train = make_newdata_category(train_df, 'Expt_mirocals')\n",
    "newdata_0_test, newdata_1_test = make_newdata_category(test_df, 'Expt_mirocals')\n",
    "\n",
    "\n",
    "# ────────────────────────────────────────────────────\n",
    "r_predict = ro.r['predict']\n",
    "\n",
    "S0_train = r_predict(fp_model, newdata=newdata_0_train, type=\"surv\")\n",
    "S1_train = r_predict(fp_model, newdata=newdata_1_train, type=\"surv\")\n",
    "\n",
    "S0_test = r_predict(fp_model, newdata=newdata_0_test, type=\"surv\")\n",
    "S1_test = r_predict(fp_model, newdata=newdata_1_test, type=\"surv\")\n",
    "\n",
    "with localconverter(default_converter + pandas2ri.converter):\n",
    "    py_S0_train = np.array(S0_train)\n",
    "    py_S1_train = np.array(S1_train)\n",
    "    py_S0_test = np.array(S0_test)\n",
    "    py_S1_test = np.array(S1_test)\n",
    "\n",
    "#_______________________________________________________\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(times, py_S0_train, label=f\"Licals\")\n",
    "plt.plot(times, py_S1_train, label=f\"Mirocals\")\n",
    "plt.plot(times, py_S0_test, label=f\"Licals (Test)\", linestyle='--')\n",
    "plt.plot(times, py_S1_test, label=f\"Mirocals (Test)\", linestyle='--')\n",
    "plt.xlabel(\"Disease Duration\")\n",
    "plt.ylabel(\"Survival probability\")\n",
    "plt.title(\"Royston–Parmar Flexible Parametric Model (rstpm2)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae5e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────\n",
    "r_predict = ro.r['predict']\n",
    "\n",
    "S0_train = r_predict(fp_model, newdata=newdata_0_train, type=\"hazard\")\n",
    "S1_train = r_predict(fp_model, newdata=newdata_1_train, type=\"hazard\")\n",
    "\n",
    "S0_test = r_predict(fp_model, newdata=newdata_0_test, type=\"hazard\")\n",
    "S1_test = r_predict(fp_model, newdata=newdata_1_test, type=\"hazard\")\n",
    "\n",
    "with localconverter(default_converter + pandas2ri.converter):\n",
    "    py_S0_train = np.array(S0_train)\n",
    "    py_S1_train = np.array(S1_train)\n",
    "    py_S0_test = np.array(S0_test)\n",
    "    py_S1_test = np.array(S1_test)\n",
    "\n",
    "#_______________________________________________________\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(times, py_S0_train, label=f\"Licals\")\n",
    "plt.plot(times, py_S1_train, label=f\"Mirocals\")\n",
    "plt.plot(times, py_S0_test, label=f\"Licals (Test)\", linestyle='--')\n",
    "plt.plot(times, py_S1_test, label=f\"Mirocals (Test)\", linestyle='--')\n",
    "plt.xlabel(\"Disease Duration\")\n",
    "plt.ylabel(\"Hazard\")\n",
    "plt.title(\"Royston–Parmar Flexible Parametric Model (rstpm2)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31249ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform likelihood ratio test between two models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f88e76d",
   "metadata": {},
   "source": [
    "## Prognostic Scores for Baseline Model (fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e69154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prognostic score (linear predictor) with standard error\n",
    "r_predict = r['predict']\n",
    "\n",
    "train_df[\"prognostic_score\"] = r_predict(fp_model, type = \"link\")\n",
    "# test_df[\"prognostic_score\"] = r_predict(fp_model, type = \"link\")\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a624cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['risk_group'] = pd.qcut(train_df['prognostic_score'], 3, labels=['Low','Medium','High'])\n",
    "\n",
    "train_df.head(6)\n",
    "train_df.risk_group.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b63a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in ['Low','Medium','High']:\n",
    "    subset = train_df[train_df['risk_group']==group]\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(subset['Disease_Duration'], subset['Event'], label=group)\n",
    "    kmf.plot_survival_function()\n",
    "plt.title(\"K–M - Prognostic Score (placebo)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend(title=\"Risk Group\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80c2e35",
   "metadata": {},
   "source": [
    "## ***Simulate Virtual Placebo***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9de4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{train_df.Event.value_counts() / train_df.Event.value_counts().sum()}\\n\")\n",
    "print(f\"{train_df['Onset_Limb'].value_counts() / train_df['Onset_Limb'].value_counts().sum()}\\n\")\n",
    "print(f\"{train_df['Sex_Male'].value_counts() / train_df['Sex_Male'].value_counts().sum()}\\n\")\n",
    "# print(f\"{train_df['Study_Arm_Placebo'].value_counts() / train_df['Study_Arm_Placebo'].value_counts().sum()}\\n\")\n",
    "print(f\"{train_df['Expt_mirocals'].value_counts() / train_df['Expt_mirocals'].value_counts().sum()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ons = train_df['Onset_Limb'].value_counts() / train_df['Onset_Limb'].value_counts().sum()\n",
    "sex = train_df['Sex_Male'].value_counts() / train_df['Sex_Male'].value_counts().sum()\n",
    "# pla = train_df['Study_Arm_Placebo'].value_counts() / train_df['Study_Arm_Placebo'].value_counts().sum()\n",
    "exp = train_df['Expt_mirocals'].value_counts() / train_df['Expt_mirocals'].value_counts().sum()\n",
    "# eur = train_df['European_Yes'].value_counts() / train_df['European_Yes'].value_counts().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb19987",
   "metadata": {},
   "outputs": [],
   "source": [
    "ons, sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aac33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca92a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545c904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e087d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = train_df[['Age', 'Expt_mirocals','Diagnostic_Delay','Vital_capacity','Sex_Male', \n",
    "            \t 'Onset_Limb','TRICALS']].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aec890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gaussian_copula_samples(n, corr):\n",
    "#     \"\"\"\n",
    "#     Draw correlated U(0,1) samples using a Gaussian copula.\n",
    "#     corr = correlation matrix (p x p).\n",
    "#     Returns: U (n x p) matrix of uniforms.\n",
    "#     \"\"\"\n",
    "#     L = np.linalg.cholesky(corr)\n",
    "#     Z = np.random.normal(size=(n, corr.shape[0]))\n",
    "#     Z_corr = Z @ L.T\n",
    "#     U = norm.cdf(Z_corr)\n",
    "#     return U\n",
    "\n",
    "\n",
    "\n",
    "# def simulate_cox_dataset(n,baseline='weibull',lam=0.1,rho=1.0,censor_rate=0.3,seed=None,var_specs=None,corr=None):\n",
    "    \"\"\"\n",
    "    Simulate a Cox proportional hazards dataset WITH correlation among covariates\n",
    "    using a Gaussian copula approach.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size.\n",
    "    baseline : {'weibull','exponential'}\n",
    "    lam : float\n",
    "        Baseline hazard parameter.\n",
    "    rho : float\n",
    "        Weibull shape parameter.\n",
    "    censor_rate : float\n",
    "        Desired censoring proportion (approx).\n",
    "    seed : int or None\n",
    "    var_specs : list of dicts\n",
    "        Each dict must include:\n",
    "            name : str\n",
    "            type : {'continuous','binary','categorical'}\n",
    "            and distribution details.\n",
    "            coef : float or dict (for categorical)\n",
    "    corr : array-like or None\n",
    "        Correlation matrix among the variables in var_specs order.\n",
    "        If None: variables are generated independently.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with:\n",
    "        time, event, true_survival_time, linear_predictor, `<covariates...>`\n",
    "    \"\"\"\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    if var_specs is None:\n",
    "        raise ValueError(\"var_specs must be provided.\")\n",
    "\n",
    "    p = len(var_specs)\n",
    "\n",
    "    # ----- STEP 1: Generate correlated uniforms -----\n",
    "    if corr is None:\n",
    "        U = None\n",
    "    else:\n",
    "        corr = np.asarray(corr)\n",
    "        if corr.shape != (p, p):\n",
    "            raise ValueError(\"corr must be p x p with p = len(var_specs)\")\n",
    "        U = gaussian_copula_samples(n, corr)\n",
    "\n",
    "    # storage\n",
    "    df = pd.DataFrame(index=np.arange(n))\n",
    "    linear_pred = np.zeros(n)\n",
    "\n",
    "    # ----- STEP 2: Generate covariates with correct marginals but correlated -----\n",
    "    for j, spec in enumerate(var_specs):\n",
    "        name = spec['name']\n",
    "        typ = spec['type'].lower()\n",
    "\n",
    "        # Uniform samples for this variable\n",
    "        uj = None if U is None else U[:, j]\n",
    "\n",
    "        # ============================================================\n",
    "        # CONTINUOUS\n",
    "        # ============================================================\n",
    "        if typ == 'continuous':\n",
    "            dist = spec.get('dist', {'kind': 'normal', 'mean': 0, 'sd': 1})\n",
    "\n",
    "            if dist['kind'] == 'normal':\n",
    "                mu = dist.get('mean', 0)\n",
    "                sd = dist.get('sd', 1)\n",
    "\n",
    "                if uj is None:\n",
    "                    x = rng.normal(mu, sd, size=n)\n",
    "                else:\n",
    "                    z = norm.ppf(uj)\n",
    "                    x = mu + sd * z\n",
    "\n",
    "            elif dist['kind'] == 'uniform':\n",
    "                lo = dist.get('low', 0)\n",
    "                hi = dist.get('high', 1)\n",
    "                if uj is None:\n",
    "                    x = rng.uniform(lo, hi, size=n)\n",
    "                else:\n",
    "                    x = lo + uj * (hi - lo)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported continuous distribution: {dist['kind']}\")\n",
    "\n",
    "            df[name] = x\n",
    "            coef = float(spec.get('coef', 0.0))\n",
    "            linear_pred += coef * x\n",
    "\n",
    "        # ============================================================\n",
    "        # BINARY\n",
    "        # ============================================================\n",
    "        elif typ == 'binary':\n",
    "            p_bin = float(spec.get('prob', 0.5))\n",
    "\n",
    "            if uj is None:\n",
    "                x = rng.binomial(1, p_bin, size=n)\n",
    "            else:\n",
    "                x = (uj < p_bin).astype(int)\n",
    "\n",
    "            df[name] = x\n",
    "            coef = float(spec.get('coef', 0.0))\n",
    "            linear_pred += coef * x\n",
    "\n",
    "        # ============================================================\n",
    "        # CATEGORICAL\n",
    "        # ============================================================\n",
    "        elif typ == 'categorical':\n",
    "            levels = list(spec['levels'])\n",
    "            probs = np.asarray(spec.get('probs', [1 / len(levels)] * len(levels)))\n",
    "\n",
    "            # boundaries for inverse-CDF categories\n",
    "            cum = np.cumsum(probs)\n",
    "\n",
    "            if uj is None:\n",
    "                cats = rng.choice(levels, p=probs, size=n)\n",
    "            else:\n",
    "                # Assign category by uniform bins\n",
    "                cats = np.empty(n, dtype=object)\n",
    "                for k, lvl in enumerate(levels):\n",
    "                    if k == 0:\n",
    "                        mask = uj <= cum[k]\n",
    "                    else:\n",
    "                        mask = (uj > cum[k - 1]) & (uj <= cum[k])\n",
    "                    cats[mask] = lvl\n",
    "\n",
    "            df[name] = pd.Categorical(cats, categories=levels)\n",
    "\n",
    "            # Add to linear predictor\n",
    "            coef_map = spec.get('coef', {})\n",
    "            ref = spec.get('ref', levels[0])\n",
    "            for lvl in levels:\n",
    "                if lvl == ref:\n",
    "                    continue\n",
    "                coef_lvl = float(coef_map.get(lvl, 0.0))\n",
    "                linear_pred += coef_lvl * (cats == lvl)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported variable type: {typ}\")\n",
    "\n",
    "    # ----- STEP 3: Generate survival times -----\n",
    "    U_time = rng.uniform(size=n)\n",
    "\n",
    "    if baseline == 'exponential' or rho == 1.0:\n",
    "        T = -np.log(U_time) / (lam * np.exp(linear_pred))\n",
    "    elif baseline == 'weibull':\n",
    "        # Weibull inverse CDF: T = (-log U)^(1/rho) / (lam*exp(lp))^(1/rho)\n",
    "        T = (-np.log(U_time)) ** (1.0 / rho) / (lam * np.exp(linear_pred)) ** (1.0 / rho)\n",
    "    else:\n",
    "        raise ValueError(\"baseline must be 'exponential' or 'weibull'\")\n",
    "\n",
    "    # ----- STEP 4: Generate censoring -----\n",
    "    # heuristic to reach the target censoring proportion\n",
    "    scale_c = max(1e-6, T.mean() * censor_rate / (1 - censor_rate + 1e-9))\n",
    "    C = rng.exponential(scale=scale_c, size=n)\n",
    "\n",
    "    observed_time = np.minimum(T, C)\n",
    "    event = (T <= C).astype(int)\n",
    "\n",
    "    # ----- STEP 5: Build output -----\n",
    "    df['time'] = observed_time\n",
    "    df['event'] = event\n",
    "    df['true_survival_time'] = T\n",
    "    df['linear_predictor'] = linear_pred\n",
    "\n",
    "    cols = ['time', 'event', 'true_survival_time', 'linear_predictor']\n",
    "    cols += [c for c in df.columns if c not in cols]\n",
    "    df = df[cols]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a96228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_coef\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df[\"Variable\"] == \"Age\", \"Estimate\"].values[0]\n",
    "# ons\n",
    "# sex[1]\n",
    "# pla[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd623ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_specs_real = [\n",
    "    # continuous\n",
    "    {'name':'Age','type':'continuous','dist':{'kind':'normal','mean':0,'sd':1},'coef':df.loc[df[\"Variable\"] == \"Age\", \"Estimate\"].values[0]},\n",
    "    {'name':'TRICALS','type':'continuous','dist':{'kind':'normal','mean':0,'sd':1},'coef':df.loc[df[\"Variable\"] == \"TRICALS\", \"Estimate\"].values[0]},\n",
    "    {'name':'Diagnostic_Delay','type':'continuous','dist':{'kind':'normal','mean':0,'sd':1},\n",
    "                                                           'coef':df.loc[df[\"Variable\"] == \"Diagnostic_Delay\", \"Estimate\"].values[0]},\n",
    "    # {'name':'Vital_capacity','type':'continuous','dist':{'kind':'normal','mean':0,'sd':1},\n",
    "    #                                                        'coef':df.loc[df[\"Variable\"] == \"Vital capacity\", \"Estimate\"].values[0]},\n",
    "\n",
    "    # binary\n",
    "    {'name':'Sex_Male','type':'binary','prob':sex[1],'coef':df.loc[df[\"Variable\"] == \"Sex_Male\", \"Estimate\"].values[0]},\n",
    "    {'name':'Onset_Limb','type':'binary','prob':ons[1],'coef':df.loc[df[\"Variable\"] == \"Onset_Limb\", \"Estimate\"].values[0]},\n",
    "    {'name':'Expt_mirocals','type':'binary','prob':exp[1],'coef':df.loc[df[\"Variable\"] == \"Expt_mirocals\", \"Estimate\"].values[0]},\n",
    "    # {'name':'Study_Arm_Placebo','type':'binary','prob':pla[1],'coef':df.loc[df[\"Variable\"] == \"Study_Arm_Placebo\", \"Estimate\"].values[0]},\n",
    "\n",
    "    # # categorical\n",
    "    # {'name':'Onset_site','type':'categorical',\n",
    "    #  'levels':['bulbar','limb','other'],'probs':[0.218484,0.746833,0.034683],\n",
    "    #  'coef':{'limb':1.151159,'other':2.508786},'ref':'bulbar'}\n",
    "]\n",
    "\n",
    "corr = train_df[['Age', 'TRICALS', 'Diagnostic_Delay','Sex_Male', 'Onset_Limb', 'Expt_mirocals']].corr()\n",
    "\n",
    "# df_sim = simulate_cox_dataset(n=df1.shape[0], baseline='weibull', lam=0.01, rho=1.5, \n",
    "#                               censor_rate=0.3, seed=42, corr=corr, var_specs=var_specs_real)\n",
    "\n",
    "\n",
    "# df_sim.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f8e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_copula_samples(n, corr):\n",
    "    \"\"\"\n",
    "    Draw correlated U(0,1) samples using a Gaussian copula.\n",
    "    corr = correlation matrix (p x p).\n",
    "    Returns: U (n x p) matrix of uniforms.\n",
    "    \"\"\"\n",
    "    L = np.linalg.cholesky(corr)\n",
    "    Z = np.random.normal(size=(n, corr.shape[0]))\n",
    "    Z_corr = Z @ L.T\n",
    "    U = norm.cdf(Z_corr)\n",
    "    return U\n",
    "\n",
    "\n",
    "def estimate_baseline_cumhaz(original_df, time_col='time', event_col='event'):\n",
    "    \"\"\"\n",
    "    Estimate baseline cumulative hazard from real data using Nelson–Aalen.\n",
    "    \"\"\"\n",
    "    naf = NelsonAalenFitter()\n",
    "    naf.fit(original_df[time_col], event_observed=original_df[event_col])\n",
    "\n",
    "    H0 = naf.cumulative_hazard_.reset_index()\n",
    "    H0.columns = ['time', 'cumhaz']\n",
    "    return H0\n",
    "\n",
    "H0_df = estimate_baseline_cumhaz(train_df, time_col='Disease_Duration', event_col='Event')\n",
    "# H0_df\n",
    "\n",
    "# def sample_survival_times_from_empirical_baseline(U, H0_df, linpred):\n",
    "#     \"\"\"\n",
    "#     Sample survival times using inverse cumulative hazard.\n",
    "\n",
    "#     U: uniform(0,1)\n",
    "#     H0_df: dataframe from estimate_baseline_cumhaz()\n",
    "#     linpred: linear predictor\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Effective cumulative hazard for each individual\n",
    "#     target = -np.log(U) / np.exp(linpred)\n",
    "\n",
    "#     # Interpolate to get survival times\n",
    "#     return np.interp(target, H0_df['cumhaz'], H0_df['time'])\n",
    "\n",
    "def sample_survival_times_from_empirical_baseline(U, H0_df, linear_pred):\n",
    "    \"\"\"\n",
    "    Inverse transform sampling using an empirical baseline cumulative hazard.\n",
    "    \"\"\"\n",
    "    H0_t = H0_df[\"time\"].values\n",
    "    H0_vals = H0_df[\"cumhaz\"].values\n",
    "\n",
    "    v = -np.log(U) / np.exp(linear_pred)\n",
    "\n",
    "    # Interpolate inverse of H0\n",
    "    T = np.interp(v, H0_vals, H0_t, left=H0_t[0], right=H0_t[-1])\n",
    "    return T\n",
    "\n",
    "def simulate_cox_dataset(n,baseline='weibull', H0_df=None,lam=0.1,rho=1.0,censor_rate=0.3,seed=None,var_specs=None,corr=None):\n",
    "    \"\"\"\n",
    "    Simulate a Cox proportional hazards dataset WITH correlation among covariates\n",
    "    using a Gaussian copula approach.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n : int\n",
    "        Sample size.\n",
    "    baseline : {'weibull','exponential'}\n",
    "    lam : float\n",
    "        Baseline hazard parameter.\n",
    "    rho : float\n",
    "        Weibull shape parameter.\n",
    "    censor_rate : float\n",
    "        Desired censoring proportion (approx).\n",
    "    seed : int or None\n",
    "    var_specs : list of dicts\n",
    "        Each dict must include:\n",
    "            name : str\n",
    "            type : {'continuous','binary','categorical'}\n",
    "            and distribution details.\n",
    "            coef : float or dict (for categorical)\n",
    "    corr : array-like or None\n",
    "        Correlation matrix among the variables in var_specs order.\n",
    "        If None: variables are generated independently.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame with:\n",
    "        time, event, true_survival_time, linear_predictor, `<covariates...>`\n",
    "    \"\"\"\n",
    "    \n",
    "    rng = np.random.default_rng(seed)\n",
    "    \n",
    "    if var_specs is None:\n",
    "        raise ValueError(\"var_specs must be provided.\")\n",
    "\n",
    "    p = len(var_specs)\n",
    "\n",
    "    # ----- STEP 1: Generate correlated uniforms -----\n",
    "    if corr is None:\n",
    "        U = None\n",
    "    else:\n",
    "        corr = np.asarray(corr)\n",
    "        if corr.shape != (p, p):\n",
    "            raise ValueError(\"corr must be p x p with p = len(var_specs)\")\n",
    "        U = gaussian_copula_samples(n, corr)\n",
    "\n",
    "    # storage\n",
    "    df = pd.DataFrame(index=np.arange(n))\n",
    "    linear_pred = np.zeros(n)\n",
    "\n",
    "    # ----- STEP 2: Generate covariates with correct marginals but correlated -----\n",
    "    for j, spec in enumerate(var_specs):\n",
    "        name = spec['name']\n",
    "        typ = spec['type'].lower()\n",
    "\n",
    "        # Uniform samples for this variable\n",
    "        uj = None if U is None else U[:, j]\n",
    "\n",
    "        # ============================================================\n",
    "        # CONTINUOUS\n",
    "        # ============================================================\n",
    "        if typ == 'continuous':\n",
    "            dist = spec.get('dist', {'kind': 'normal', 'mean': 0, 'sd': 1})\n",
    "\n",
    "            if dist['kind'] == 'normal':\n",
    "                mu = dist.get('mean', 0)\n",
    "                sd = dist.get('sd', 1)\n",
    "\n",
    "                if uj is None:\n",
    "                    x = rng.normal(mu, sd, size=n)\n",
    "                else:\n",
    "                    z = norm.ppf(uj)\n",
    "                    x = mu + sd * z\n",
    "\n",
    "            elif dist['kind'] == 'uniform':\n",
    "                lo = dist.get('low', 0)\n",
    "                hi = dist.get('high', 1)\n",
    "                if uj is None:\n",
    "                    x = rng.uniform(lo, hi, size=n)\n",
    "                else:\n",
    "                    x = lo + uj * (hi - lo)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported continuous distribution: {dist['kind']}\")\n",
    "\n",
    "            df[name] = x\n",
    "            coef = float(spec.get('coef', 0.0))\n",
    "            linear_pred += coef * x\n",
    "\n",
    "        # ============================================================\n",
    "        # BINARY\n",
    "        # ============================================================\n",
    "        elif typ == 'binary':\n",
    "            p_bin = float(spec.get('prob', 0.5))\n",
    "\n",
    "            if uj is None:\n",
    "                x = rng.binomial(1, p_bin, size=n)\n",
    "            else:\n",
    "                x = (uj < p_bin).astype(int)\n",
    "\n",
    "            df[name] = x\n",
    "            coef = float(spec.get('coef', 0.0))\n",
    "            linear_pred += coef * x\n",
    "\n",
    "        # ============================================================\n",
    "        # CATEGORICAL\n",
    "        # ============================================================\n",
    "        elif typ == 'categorical':\n",
    "            levels = list(spec['levels'])\n",
    "            probs = np.asarray(spec.get('probs', [1 / len(levels)] * len(levels)))\n",
    "\n",
    "            # boundaries for inverse-CDF categories\n",
    "            cum = np.cumsum(probs)\n",
    "\n",
    "            if uj is None:\n",
    "                cats = rng.choice(levels, p=probs, size=n)\n",
    "            else:\n",
    "                # Assign category by uniform bins\n",
    "                cats = np.empty(n, dtype=object)\n",
    "                for k, lvl in enumerate(levels):\n",
    "                    if k == 0:\n",
    "                        mask = uj <= cum[k]\n",
    "                    else:\n",
    "                        mask = (uj > cum[k - 1]) & (uj <= cum[k])\n",
    "                    cats[mask] = lvl\n",
    "\n",
    "            df[name] = pd.Categorical(cats, categories=levels)\n",
    "\n",
    "            # Add to linear predictor\n",
    "            coef_map = spec.get('coef', {})\n",
    "            ref = spec.get('ref', levels[0])\n",
    "            for lvl in levels:\n",
    "                if lvl == ref:\n",
    "                    continue\n",
    "                coef_lvl = float(coef_map.get(lvl, 0.0))\n",
    "                linear_pred += coef_lvl * (cats == lvl)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported variable type: {typ}\")\n",
    "\n",
    "    # ----- STEP 3: Generate survival times -----\n",
    "    U_time = rng.uniform(size=n)\n",
    "\n",
    "    if baseline == \"empirical\":\n",
    "        if H0_df is None:\n",
    "            raise ValueError(\"You must supply H0_df when using empirical baseline.\")\n",
    "        T = sample_survival_times_from_empirical_baseline(U_time, H0_df, linear_pred)\n",
    "\n",
    "    elif baseline == 'exponential' or rho == 1.0:\n",
    "        T = -np.log(U_time) / (lam * np.exp(linear_pred))\n",
    "\n",
    "    elif baseline == 'weibull':\n",
    "        T = (-np.log(U_time)) ** (1.0 / rho) / (lam * np.exp(linear_pred)) ** (1.0 / rho)\n",
    "    else:\n",
    "        raise ValueError(\"baseline must be 'exponential' or 'weibull'\")\n",
    "\n",
    "    # ----- STEP 4: Generate censoring -----\n",
    "    # heuristic to reach the target censoring proportion\n",
    "    scale_c = max(1e-6, T.mean() * censor_rate / (1 - censor_rate + 1e-9))\n",
    "    C = rng.exponential(scale=scale_c, size=n)\n",
    "\n",
    "    observed_time = np.minimum(T, C)\n",
    "    event = (T <= C).astype(int)\n",
    "\n",
    "    # ----- STEP 5: Build output -----\n",
    "    df['time'] = observed_time\n",
    "    df['event'] = event\n",
    "    df['true_survival_time'] = T\n",
    "    df['linear_predictor'] = linear_pred\n",
    "\n",
    "    cols = ['time', 'event', 'true_survival_time', 'linear_predictor']\n",
    "    cols += [c for c in df.columns if c not in cols]\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98bf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Event.value_counts() / train_df.Event.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465f28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real dataset\n",
    "# H0_df = estimate_baseline_cumhaz(real_df)\n",
    "\n",
    "# Simulated dataset\n",
    "sim_df = simulate_cox_dataset(\n",
    "    # n=500,\n",
    "    n=train_df.shape[0],\n",
    "    var_specs=var_specs_real,\n",
    "    corr=corr,\n",
    "    baseline=\"empirical\",\n",
    "    H0_df=H0_df,\n",
    "    censor_rate=0.4,\n",
    "    seed=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeebee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab858de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactions\n",
    "sim_df['Sex_onset'] = sim_df['Sex_Male']*sim_df['Onset_Limb']\n",
    "sim_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.event.value_counts() #/ sim_df.event.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e9615",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Event.value_counts() #/ train_df.event.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf32a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ons = train_df['Onset_Limb'].value_counts() / train_df['Onset_Limb'].value_counts().sum()\n",
    "sex = train_df['Sex_Male'].value_counts() / train_df['Sex_Male'].value_counts().sum()\n",
    "# sex_ons = train_df['Sex_onset'].value_counts() / train_df['Sex_onset'].value_counts().sum()\n",
    "print(ons, sex)\n",
    "\n",
    "print(\"\\n---- Simulated data ----\")\n",
    "ons1 = sim_df['Onset_Limb'].value_counts() / sim_df['Onset_Limb'].value_counts().sum()\n",
    "sex1 = sim_df['Sex_Male'].value_counts() / sim_df['Sex_Male'].value_counts().sum()\n",
    "# sex_ons1 = sim_df['Sex_onset'].value_counts() / sim_df['Sex_onset'].value_counts().sum()\n",
    "\n",
    "print(ons1, sex1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb435f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Expt_mirocals', 'Onset_Limb', 'Sex_Male']\n",
    "for col in cols:\n",
    "    print(f'{col}: {sim_df[col].value_counts().to_dict()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95280931",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09935f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with conversion.localconverter(pandas2ri.converter):\n",
    "    r_df_sim = pandas2ri.py2rpy(sim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd86b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the formula\n",
    "formula1 = Formula('Surv(true_survival_time, event==1) ~ Age + Onset_Limb + TRICALS + Sex_Male + Expt_mirocals + Diagnostic_Delay')\n",
    "\n",
    "# Fit the flexible parametric model\n",
    "# df = degrees of freedom for spline, adjust as needed\n",
    "fp_model1 = rstpm2.stpm2(formula1, data=r_df_sim, df=0)\n",
    "print(ro.r.summary(fp_model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coefficients directly\n",
    "summary1 = ro.r.summary(fp_model1)\n",
    "\n",
    "# Try using slotNames to see what's available\n",
    "# print(\"Available slots:\", ro.r.slotNames(summary))\n",
    "\n",
    "# Extract using the correct slot name (usually 'coef' or 'coefficients')\n",
    "coefficients1 = summary1.slots['coef']\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df_coef1 = pd.DataFrame(\n",
    "    np.array(coefficients1),\n",
    "    columns=['Estimate', 'Std. Error', 'z value', 'Pr(z)'],\n",
    "    index=list(coefficients1.rownames)\n",
    ")\n",
    "\n",
    "df_coef1 = df_coef1.iloc[1: -1]\n",
    "df_coef1 = df_coef1.reset_index().rename(columns={\"index\": \"Variable\"})\n",
    "\n",
    "\n",
    "print(df_coef1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a107c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4704754",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = pd.merge(df_coef, df_coef1, on=\"Variable\", suffixes=('_real', '_simulated'))\n",
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs1 = coefs[['Variable', 'Estimate_real', 'Estimate_simulated']]\n",
    "coefs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(coefs1))      # positions\n",
    "width = 0.35                # bar width\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Bars\n",
    "plt.bar(x - width/2, coefs1[\"Estimate_real\"], width, label=\"Original Data\")\n",
    "plt.bar(x + width/2, coefs1[\"Estimate_simulated\"], width, label=\"Simulated Data\")\n",
    "\n",
    "# Zero line\n",
    "plt.axhline(0, linestyle=\"--\", linewidth=1)\n",
    "\n",
    "# Labels\n",
    "plt.xticks(x, coefs1[\"Variable\"], rotation=45, ha=\"right\")\n",
    "plt.ylabel(\"Coefficient value\")\n",
    "plt.title(\"Bar Plot of Coefficients: Original vs Simulated Data\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['Age', 'TRICALS', 'Diagnostic_Delay']:  # replace with your continuous columns\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.hist(df1[col], bins=30, alpha=0.5, label='Original', density=True)\n",
    "    plt.hist(sim_df[col], bins=30, alpha=0.5, label='Simulated', density=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc14687",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Age', 'TRICALS', 'Diagnostic_Delay']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "# Original correlation\n",
    "sns.heatmap(df1[cols].corr(), annot=True, cmap=\"coolwarm\", ax=axes[0], vmin=-1, vmax=1)\n",
    "axes[0].set_title(\"Original Correlation Matrix\")\n",
    "\n",
    "# Simulated correlation\n",
    "sns.heatmap(sim_df[cols].corr(), annot=True, cmap=\"coolwarm\", ax=axes[1], vmin=-1, vmax=1)\n",
    "axes[1].set_title(\"Simulated Correlation Matrix\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dba632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "cols = ['Age', 'TRICALS', 'Diagnostic_Delay']\n",
    "\n",
    "results = []\n",
    "\n",
    "for col in cols:\n",
    "    original = df1[col].dropna()\n",
    "    simulated = sim_df[col].dropna()\n",
    "\n",
    "    # Welch t-test\n",
    "    t_stat, p_val = ttest_ind(original, simulated, equal_var=False)\n",
    "\n",
    "    # Mean difference\n",
    "    mean_diff = simulated.mean() - original.mean()\n",
    "\n",
    "    # Standard errors for CI (Welch)\n",
    "    se = np.sqrt(original.var()/len(original) + simulated.var()/len(simulated))\n",
    "\n",
    "    # 95% CI\n",
    "    ci_low = mean_diff - 1.96 * se\n",
    "    ci_high = mean_diff + 1.96 * se\n",
    "\n",
    "    results.append([col, mean_diff, ci_low, ci_high, p_val])\n",
    "\n",
    "df_plot = pd.DataFrame(results, columns=[\"Variable\", \"MeanDiff\", \"CI_low\", \"CI_high\", \"p_value\"])\n",
    "\n",
    "\n",
    "# --------- Forest Plot ---------\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "y_pos = np.arange(len(df_plot))\n",
    "\n",
    "plt.errorbar(\n",
    "    df_plot[\"MeanDiff\"], \n",
    "    y_pos, \n",
    "    xerr=[df_plot[\"MeanDiff\"] - df_plot[\"CI_low\"], df_plot[\"CI_high\"] - df_plot[\"MeanDiff\"]],\n",
    "    fmt='o', \n",
    "    capsize=5\n",
    ")\n",
    "\n",
    "plt.axvline(0, color='gray', linestyle='--')\n",
    "\n",
    "plt.yticks(y_pos, df_plot[\"Variable\"])\n",
    "plt.xlabel(\"Mean Difference (Simulated − Original)\")\n",
    "plt.title(\"Forest Plot of T-Test Mean Differences\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the interaction term from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e16e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ee4d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digital_twins_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
